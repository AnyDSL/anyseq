static BLOCK_WIDTH = 128;
static BLOCK_HEIGHT = BLOCK_WIDTH*10;

struct IterationInfo{
    bid_x:  Index,
    tid_x:  Index
}

fn get_iteration_info(bid_x: Index, tid_x: Index) -> IterationInfo {
    IterationInfo{
        bid_x:  bid_x,
        tid_x:  tid_x
    }
}

fn @iteration(query_gpu: Sequence, subject_gpu: Sequence, scores: ScoringMatrix, predc: PredecessorMatrix, body: RelaxationBody) -> () {
    
    let acc = accelerator(device_id);

    let num_blocks_i = round_up_div(query_gpu.length, BLOCK_HEIGHT);
    let num_blocks_j = round_up_div(subject_gpu.length, BLOCK_WIDTH);
    let max_blocks = min(num_blocks_i, num_blocks_j);
    let block_diags = num_blocks_i + num_blocks_j - 1;
    
    let block = (BLOCK_WIDTH, 1, 1);

    for benchmark_acc(acc){
        
        //iterate over diagonals of blocks
        for block_dia_i in range(0, block_diags){
        
            let num_blocks = min3(block_dia_i + 1, max_blocks, block_diags - block_dia_i);
        
            let grid  = (num_blocks * BLOCK_WIDTH, 1, 1);
            
            //execute kernel for each diagonal
            for tid, bid, bdim, gdim, gid in acc.exec(grid, block) {
                
                let (tidx,  _,  _) = tid;
                let (bidx,  _,  _) = bid;

                let tid_x = tidx();
                let block_dia_j = bidx();
                let block_i = min(block_dia_i, num_blocks_i - 1) - block_dia_j;
                let block_j = max(block_dia_i - num_blocks_i + 1, 0) + block_dia_j;

                let offset_i = block_i * BLOCK_HEIGHT;
                let offset_j = block_j * BLOCK_WIDTH;

                let height = min(query_gpu.length - offset_i, BLOCK_HEIGHT);
                let width  = min(subject_gpu.length - offset_j, BLOCK_WIDTH);

                let que_acc_gl = get_sequence_acc_offset(read_sequence(query_gpu), write_sequence(query_gpu), offset_i);
                let sub_acc_gl = get_sequence_acc_offset(read_sequence(subject_gpu), write_sequence(subject_gpu), offset_j);

                let que_acc = sequence_to_shared(tid_x, query_gpu, BLOCK_HEIGHT, que_acc_gl);
                let sub_acc = sequence_to_shared(tid_x, subject_gpu, BLOCK_WIDTH, sub_acc_gl);

                let sco_acc = scores.get_iteration_acc(offset_i, offset_j, height, width, false, get_iteration_info(block_dia_j, tid_x)); 
                let pre_acc = predc.get_iteration_acc(offset_i, offset_j, height, width, get_iteration_info(block_dia_j, tid_x));      

                let diags = BLOCK_WIDTH + BLOCK_HEIGHT - 1;

                //iterate over diagonals of matrix entries
                for dia_i in range(0, diags){

                    acc.barrier();

                    let j = tid_x;
                    let i = dia_i - j;

                    sco_acc.update_begin_line(i);
                    
                    if i >= 0 && i < BLOCK_HEIGHT {
                        body(i, j, que_acc, sub_acc, sco_acc, pre_acc);
                    }

                    sco_acc.update_end_line(i);
                }
                sco_acc.block_end();
            }
            acc.sync();
        }
    }
}

fn iteration_partitioned(half_size: Index, num_halfs: Index, block_width: Index, splits: Splits, max_part_height: Index) -> IterationFn{
    
    |query, subject, scores, predc, body| {

        let acc = accelerator(device_id);

        //horizontal blocks in each half
        let half_num_blocks_j = half_size / block_width;
        //vertical blocks in each half
        let half_num_blocks_i = round_up_div(max_part_height, BLOCK_HEIGHT);
        //maximum blocks in one antidiagonal of a half
        let half_max_blocks = min(half_num_blocks_i, half_num_blocks_j);
        //amount of antidiagonals in a half
        let block_diags = half_num_blocks_i + half_num_blocks_j - 1;
    
        let block = (BLOCK_WIDTH, 1, 1);

        for benchmark_acc(acc){
            //iterate over diagonals of blocks
            for block_dia_i in range(0, block_diags){

                let half_num_blocks = min3(block_dia_i + 1, half_max_blocks, block_diags - block_dia_i);
                let grid  = (half_num_blocks * num_halfs * BLOCK_WIDTH, 1, 1);
            
                //execute kernel for each diagonal
                for tid, bid, bdim, gdim, gid in acc.exec(grid, block) {
                
                    let (tidx,  _,  _) = tid;
                    let (bidx,  _,  _) = bid;

                    let tid_x = tidx();
                    let block_dia_j = bidx();

                    let half_index = block_dia_j / half_num_blocks;
                    let is_left_half = half_index % 2 == 0;

                    let half_block_dia_j = block_dia_j % half_num_blocks;
                    let half_block_i = min(block_dia_i, half_num_blocks_i - 1) - half_block_dia_j;
                    let half_block_j = max(block_dia_i - half_num_blocks_i + 1, 0) + half_block_dia_j;
                
                    let half_offset_j = half_index * half_size;
                    let (half_offset_i, half_height) = splits.get_part_dimensions(half_index / 2);

                    let offset_i = half_offset_i + half_block_i * BLOCK_HEIGHT;
                    let offset_j = half_offset_j + half_block_j * block_width;

                    let half_width  = min(half_size, subject.length - half_offset_j);

                    let height = min(BLOCK_HEIGHT, half_height - half_block_i * BLOCK_HEIGHT);
                    let width  = min(block_width, subject.length - offset_j);

                    if width > 0 && height > 0{

                        let que_acc = get_sequence_acc_half(query, half_offset_i, half_height, half_block_i, BLOCK_HEIGHT, is_left_half);
                        let sub_acc = get_sequence_acc_half(subject, half_offset_j, half_width, half_block_j, block_width, is_left_half);

                        let sco_acc = scores.get_iteration_acc(offset_i, offset_j, height, width, is_left_half, get_iteration_info(block_dia_j, tid_x)); 
                        let pre_acc = predc.get_iteration_acc(offset_i, offset_j, height, width, get_iteration_info(block_dia_j, tid_x));      

                        let diags = height + width - 1;
                
                        let j = tid_x;

                        //iterate over diagonals of matrix entries
                        for dia_i in range(0, diags){

                            acc.barrier();

                            let i = dia_i - j;

                            sco_acc.update_begin_line(i);
                    
                            if i >= 0 && i < height && j < width{
                                body(i, j, que_acc, sub_acc, sco_acc, pre_acc);
                            }

                            sco_acc.update_end_line(i);
                        }
                        sco_acc.block_end();
                    }
                }
                acc.sync();
            }
        }
    }
}

fn iteration_blockwise(block_width: Index, splits: Splits) -> IterationFn {

    |query, subject, scores, predc, body| {
        let acc = accelerator(device_id);

        let num_blocks = round_up_div(subject.length, block_width);

        let block = (block_width, 1, 1);
        let grid  = (num_blocks * block_width, 1, 1);

        for tid, bid, bdim, gdim, gid in acc.exec(grid, block) {
                
            let (tidx,  _,  _) = tid;
            let (bidx,  _,  _) = bid;

            let tid_x = tidx();
            let block_j = bidx();

            let (offset_i, height) = splits.get_part_dimensions(block_j);
            let offset_j = block_j * block_width;

            let width = min(block_width, subject.length - offset_j);

            let que_acc = get_sequence_acc_offset(read_sequence(query), write_sequence(query), offset_i);
            let sub_acc = get_sequence_acc_offset(read_sequence(subject), write_sequence(subject), offset_j);

            let sco_acc = scores.get_iteration_acc(offset_i, offset_j, height, width, false, get_iteration_info(block_j, tid_x)); 
            let pre_acc = predc.get_iteration_acc(offset_i, offset_j, height, width, get_iteration_info(block_j, tid_x));      

            let diags = width + height - 1;

            for dia_i in range(0, diags){

                acc.barrier();

                let j = tid_x;
                let i = dia_i - j;

                sco_acc.update_begin_line(i);
                    
                if i >= 0 && i < height{
                    body(i, j, que_acc, sub_acc, sco_acc, pre_acc);
                }

                sco_acc.update_end_line(i);
            }
            sco_acc.block_end();
        }
        acc.sync();
    }
}

fn iteration_tb(predc_cpu: MatrixS, splits: Splits, subject_length: Index, block_width: Index, body: fn (MatrixSAcc, Index, Index, Index, Index) -> ()) -> (){
    let splits_gpu = splits.get_splits_vector();
    let splits_cpu = alloc_vector(splits_gpu, alloc_cpu);
    copy_vector(splits_gpu, splits_cpu);

    let spl_acc = get_vector_acc_cpu(splits_cpu);

    let mut offset_i = 0;
    let mut end_i    = 0;
    
    for block in range(0, splits_cpu.length){

        offset_i = end_i;
        end_i    = spl_acc.read(block);

        let offset_j = block * block_width;
        let predc_offset_i = offset_i + block;

        let height = end_i - offset_i;
        let width = min(block_width, subject_length - offset_j);

        let pre_acc = get_matrix_s_acc_offset(predc_cpu, read_matrix_s_cpu(predc_cpu), write_matrix_s_cpu(predc_cpu), predc_offset_i, 0);
        body(pre_acc, offset_i, offset_j, height, width);
    }

    release(splits_cpu.buf);

}


fn iteration_1d(length: Index, body: fn(Index) -> ()) -> (){
    
    let acc = accelerator(device_id);
    
    let num_blocks = round_up_div(length, BLOCK_WIDTH);
    let block = (BLOCK_WIDTH, 1, 1);
    let grid  = (num_blocks * BLOCK_WIDTH, 1, 1);

    for tid, bid, bdim, gdim, gid in acc.exec(grid, block) {
        let (gidx,  _,  _) = gid;
        body(gidx());
    }
}

fn iteration_matrix_1d(matrix: Matrix, length: Index, body: fn(Index, MatrixAcc) -> ()) -> (){
    
    let mat_acc = make_matrix_acc(matrix, read_matrix(matrix), write_matrix(matrix));
    
    for i in iteration_1d(length){
        body(i, mat_acc);
    }
}

fn iteration_matrix_s_1d(matrix: MatrixS, length: Index, body: fn(Index, MatrixSAcc) -> ()) -> (){
    
    let mat_acc = get_matrix_s_acc(matrix, read_matrix_s(matrix), write_matrix_s(matrix));
    
    for i in iteration_1d(length){
        body(i, mat_acc);
    }
}


fn iteration_vector_1d(vector: Vector, length: Index, body: fn(Index, VectorAcc) -> ()) -> (){
    
    let vec_acc = get_vector_acc(read_vector(vector), write_vector(vector));

    for i in iteration_1d(length){
        body(i, vec_acc);
    }
}

fn iteration_2_vectors_1d(vector_1: Vector, vector_2: Vector, length: Index, body: fn(Index, VectorAcc, VectorAcc) -> ()) -> (){

    let vec_1_acc = get_vector_acc(read_vector(vector_1), write_vector(vector_1));
    let vec_2_acc = get_vector_acc(read_vector(vector_2), write_vector(vector_2));

    for i in iteration_1d(length){
        body(i, vec_1_acc, vec_2_acc);
    }
}

static OPS_PER_THREAD_REDUCTION = 1;

struct ReductionData{
    reduce_global: fn(Index, Index) -> (),
    reduce_shared: fn(Index, Index) -> (),
    out:           fn(Index) -> ()
}

fn iteration_reduction(vector_gpu: Vector, index_cpu: Vector, score_cpu: Vector, offset: Index, length: Index, body: fn(Score, Score) -> bool) -> (){

    let acc = accelerator(device_id);
    let mut swap = true;

    let mut len = length;
    
    let vector_1  = create_vector(round_up_div(length, BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION) * BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION, 0, acc.alloc);
    let vector_2  = create_vector(round_up_div(length, BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION), 0, acc.alloc);
    let indices_1 = alloc_vector(vector_gpu, acc.alloc);
    let indices_2 = alloc_vector(vector_2, acc.alloc); 
    
    copy_vector_offset(vector_gpu, offset + 1, vector_1, 1, length - 1);
    for i, vec_acc in iteration_vector_1d(indices_1, indices_1.length + 1){
        vec_acc.write(i, i + offset);
    }

    while len > 1 {

        let vector_in   = if swap { vector_1  } else { vector_2  };
        let vector_out  = if swap { vector_2  } else { vector_1  };
        let indices_in  = if swap { indices_1 } else { indices_2 };
        let indices_out = if swap { indices_2 } else { indices_1 };
        swap = !swap;

        let vec_in_acc  = get_vector_acc(read_vector(vector_in), write_vector(vector_in));
        let vec_out_acc = get_vector_acc(read_vector(vector_out), write_vector(vector_out));
        let ind_in_acc  = get_vector_acc(read_vector(indices_in), write_vector(indices_in));
        let ind_out_acc = get_vector_acc(read_vector(indices_out), write_vector(indices_out));

        for tid_x in reduction_kernel(len){

            let vector_shared  = reserve_shared[MatrixElem](BLOCK_WIDTH);
            let indices_shared = reserve_shared[MatrixElem](BLOCK_WIDTH);
            vector_shared(tid_x) = SCORE_MIN_VALUE;

            ReductionData{
                reduce_global: |global_i, shared_i| {
                    let v = vec_in_acc.read(global_i);
                    let v_i = ind_in_acc.read(global_i);
                    if body(v, vector_shared(shared_i)){
                        vector_shared(shared_i) = v;
                        indices_shared(shared_i) = v_i;
                    }
                },
                reduce_shared: |index_1, index_2| {
                    let v = vector_shared(index_1);
                    let v_i = indices_shared(index_1);
                    if body(v, vector_shared(index_2)){
                        vector_shared(index_2) = v;
                        indices_shared(index_2) = v_i;
                    }
                },
                out: |out_index| {
                    vec_out_acc.write(out_index, vector_shared(0));
                    ind_out_acc.write(out_index, indices_shared(0));
                }
            }
        }
        len = round_up_div(len, BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION);
    }
    let indices_out = if swap { indices_1 } else { indices_2 };
    copy_vector(indices_out, index_cpu);
    let vector_out = if swap { vector_1 } else { vector_2 };
    copy_vector(vector_out, score_cpu);
    
    release(vector_1.buf);
    release(vector_2.buf);
    release(indices_1.buf);
    release(indices_2.buf);
}

fn iteration_sum_reduction(vector_gpu: Vector, index_cpu: Vector, score_cpu: Vector, offset: Index, length: Index, body: fn(Score, Score) -> bool) -> (){

    let acc = accelerator(device_id);
    let mut swap = true;

    let mut len = length;
    
    let vector_1  = create_vector(round_up_div(length, BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION) * BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION, 0, acc.alloc);
    let vector_2  = create_vector(round_up_div(length, BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION), 0, acc.alloc);
    let indices_1 = alloc_vector(vector_gpu, acc.alloc);
    let indices_2 = alloc_vector(vector_2, acc.alloc); 
    
    copy_vector_offset(vector_gpu, offset + 1, vector_1, 1, length - 1);
    for i, vec_acc in iteration_vector_1d(indices_1, indices_1.length + 1){
        vec_acc.write(i, i + offset);
    }

    while len > 1 {

        let vector_in   = if swap { vector_1  } else { vector_2  };
        let vector_out  = if swap { vector_2  } else { vector_1  };
        let indices_in  = if swap { indices_1 } else { indices_2 };
        let indices_out = if swap { indices_2 } else { indices_1 };
        swap = !swap;

        let vec_in_acc  = get_vector_acc(read_vector(vector_in), write_vector(vector_in));
        let vec_out_acc = get_vector_acc(read_vector(vector_out), write_vector(vector_out));
        let ind_in_acc  = get_vector_acc(read_vector(indices_in), write_vector(indices_in));
        let ind_out_acc = get_vector_acc(read_vector(indices_out), write_vector(indices_out));

        for tid_x in reduction_kernel(len){

            let vector_shared  = reserve_shared[MatrixElem](BLOCK_WIDTH);
            let indices_shared = reserve_shared[MatrixElem](BLOCK_WIDTH);
            vector_shared(tid_x) = SCORE_MIN_VALUE;

            ReductionData{
                reduce_global: |global_i, shared_i| {
                    let v = vec_in_acc.read(global_i);
                    let v_i = ind_in_acc.read(global_i);
                    if body(v, vector_shared(shared_i)){
                        vector_shared(shared_i) = v;
                        indices_shared(shared_i) = v_i;
                    }
                },
                reduce_shared: |index_1, index_2| {
                    let v = vector_shared(index_1);
                    let v_i = indices_shared(index_1);
                    if body(v, vector_shared(index_2)){
                        vector_shared(index_2) = v;
                        indices_shared(index_2) = v_i;
                    }
                },
                out: |out_index| {
                    vec_out_acc.write(out_index, vector_shared(0));
                    ind_out_acc.write(out_index, indices_shared(0));
                }
            }
        }
        len = round_up_div(len, BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION);
    }
    let indices_out = if swap { indices_1 } else { indices_2 };
    copy_vector(indices_out, index_cpu);
    let vector_out = if swap { vector_1 } else { vector_2 };
    copy_vector(vector_out, score_cpu);
    
    release(vector_1.buf);
    release(vector_2.buf);
    release(indices_1.buf);
    release(indices_2.buf);
}


    

fn reduction_kernel(length: Index, get_data: fn(Index) -> ReductionData) -> (){

    let acc = accelerator(device_id);
        
    let num_blocks = round_up_div(length, BLOCK_WIDTH * OPS_PER_THREAD_REDUCTION);
    let block = (BLOCK_WIDTH, 1, 1);
    let grid  = (num_blocks * BLOCK_WIDTH, 1, 1);

    for tid, bid, bdim, gdim, gid in acc.exec(grid, block) {

        let (tidx,  _,  _) = tid;
        let (bidx,  _,  _) = bid;
        let (gdimx,  _,  _) = gdim;

        let bid_x = bidx();
        let tid_x = tidx();
        let gdim_x = gdimx();

        let data = get_data(tid_x);

        let mut i = bid_x * BLOCK_WIDTH + tid_x;

        while i < length {
            data.reduce_global(i, tid_x);
            i += gdim_x;
        }
                        
        let mut s = BLOCK_WIDTH / 2;
        while s > 0 {
            acc.barrier();
            if(tid_x < s) {
                data.reduce_shared(tid_x + s, tid_x);
            }
            s /= 2;
        }
        if tid_x == 0 {
            data.out(bid_x);
        }
    }
    acc.sync();
}
